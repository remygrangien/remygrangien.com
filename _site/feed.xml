<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-03-30T14:12:07+11:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Remy Grangien</title><subtitle>Here you can find my thoughts on artificial intelligence and other topics.</subtitle><author><name>Remy Grangien</name></author><entry><title type="html">Blackbirds and pigeons</title><link href="http://localhost:4000/blackbirds-and-pigeons.html" rel="alternate" type="text/html" title="Blackbirds and pigeons" /><published>2021-03-29T00:00:00+11:00</published><updated>2021-03-29T00:00:00+11:00</updated><id>http://localhost:4000/blackbirds-and-pigeons</id><content type="html" xml:base="http://localhost:4000/blackbirds-and-pigeons.html">&lt;p&gt;In &lt;em&gt;Philosophy of Mind: Body, Brian and Behaviour&lt;/em&gt; by Slor et al. (2015), I came across a thought experiment of interest, which I paraphrase here:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is a foggy morning. As you look outside your window, you see a bird sitting on a branch of a tree. You mistake the bird for a blackbird, when it is in fact a pigeon.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Of the comments made by the authors, this struck me as particularly misleading:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Once a token of PIGEON in your head has been caused by a blackbird, tokens of the PIGEON type obtain the meaning ‘pigeon-or-blackbird’. The undesirable consequence is that you are not making a mistake when you instantiate a token of PIGEON in response to seeing a blackbird.” (Slor et al. pp.127)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is taken to be an argument against resemblance theories of intentional content, and I believe it stems from a misunderstanding of how the brain recognises objects.&lt;/p&gt;

&lt;p&gt;To operate efficiently in the world, the brain must reuse features in its identification of objects. These shared features can be as fundamental as edge detection, but also as complex as the presence of legs, of particularly coloured or textured plumage, etc. And so the model that belies the token PIGEON, while it is in totality different from BLACKBIRD, shares many of the same features, because blackbirds and pigeons share these features in the world. An attempt to engineer object recognition is not needed to demonstrate this, but merely our own robust object detection observed: a pigeon is in some ways less similar to another pigeon when compared to a blackbird with the same number of feathers, or legs, yet we can still tell that what we are looking at is a pigeon, and not a blackbird, because there is overall enough differing features, or combinations of certain features, presented for differentiation, and thus identification.&lt;/p&gt;

&lt;p&gt;That our ability to classify objects requires generalised models is a widely held belief, however we must still address the worry that these models of classes are flimsy, such that our model of a pigeon may as well be a model of a blackbird when we fail to classify a pigeon correctly.&lt;/p&gt;

&lt;p&gt;In the particular scenario presented to us, the key to diffusing this worry is the presence of the fog. This is because, without the fog or any other obscurant, if we still misidentify the bird, we must ask ourselves whether we do indeed have different models for blackbirds and pigeons. If no amount of clarity of features can produce a definitive decision, then it’s because those features have not been well associated with the relevant token.&lt;/p&gt;

&lt;p&gt;This intuition can be demonstrated in reverse, and provides us a different and useful premise. Say you know nothing about either pigeons and blackbirds, other than that they are types of birds. Your friend that does know the difference would like to help you learn, and so he has prepared a deck of labelled photographs of these birds. However, the friend has been unhelpful: each photo he has taken is of a bird heavily obscured by fog, such that no definitive features of the birds can be readily extracted (they are however photographs of real pigeons and blackbirds that he has taken, and he has labelled them correctly based on his further observations after the taking of the images). What little features can be identified are not so useful, because the number of photographs he has provided is so small when compared to their quality. In this example, I hope the intuition is that tokens for blackbird and pigeon are not learned, despite there being labelled examples of each provided. We may now suggest that, in the case where misidentification occurs:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;It occurred because the features were not clear.&lt;/li&gt;
  &lt;li&gt;In the case where features are not clear, the relevant models are not significantly updated, i.e. nothing is learned.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Remy Grangien</name></author><summary type="html">In Philosophy of Mind: Body, Brian and Behaviour by Slor et al. (2015), I came across a thought experiment of interest, which I paraphrase here:</summary></entry></feed>